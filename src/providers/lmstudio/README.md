# LM Studio Provider

Provider implementation for [LM Studio](https://lmstudio.ai/) - a desktop application for running quantized models.

## Features

- ✅ Model listing
- ✅ Streaming responses
- ✅ Connection testing
- ✅ OpenAI-compatible API

## Default Configuration

- **Base URL**: `http://localhost:1234`
- **API Endpoint**: `/v1/chat/completions`

## Usage

1. Download and install [LM Studio](https://lmstudio.ai/)
2. Load a model in LM Studio
3. Start the local server in LM Studio
4. Connect from OpenChat

## Supported Features

- OpenAI-compatible API
- Streaming responses
- Model management
- Temperature and sampling controls
